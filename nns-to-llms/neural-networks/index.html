
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../decision-making-and-nns/">
      
      
        <link rel="next" href="../../math-for-ml/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.7">
    
    
      
        <title>Neural Networks - Second book</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.f2e4d321.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 13h-4v4h-2v-4H7v-2h4V7h2v4h4m-5-9A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2Z"/></svg>');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Andika:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Andika";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#learning-to-make-decisions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Second book" class="md-header__button md-logo" aria-label="Second book" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Second book
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neural Networks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/dsa-book/non-executable" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    dsa-book/non-executable
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../.." class="md-tabs__link">
          
  
  Essential AI Home

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  NNs to LLMs

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../math-for-ml/" class="md-tabs__link">
          
  
  Math for ML/DL

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Second book" class="md-nav__button md-logo" aria-label="Second book" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Second book
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dsa-book/non-executable" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    dsa-book/non-executable
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Essential AI Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Essential AI Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Essential AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About Me
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    NNs to LLMs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            NNs to LLMs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decision-making-and-nns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision Making and Neurons
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Neural Networks
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Neural Networks
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#making-perceptron-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Making Perceptron Learn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-activation" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Activation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#we-have-sigmoid-neurons" class="md-nav__link">
    <span class="md-ellipsis">
      We have Sigmoid Neurons
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#coding-feedforward-neural-networks-without-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Coding FeedForward Neural Networks (without learning)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lets-make-a-neural-network-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Let's make a Neural Network Learn.
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Let's make a Neural Network Learn.">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-beauty-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      The beauty of Neural Networks.
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-problem-and-the-dataset-setup" class="md-nav__link">
    <span class="md-ellipsis">
      The problem and the dataset setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The problem and the dataset setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-not-a-rule-based-approach" class="md-nav__link">
    <span class="md-ellipsis">
      Why not a rule-based approach?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-plan" class="md-nav__link">
    <span class="md-ellipsis">
      The Plan
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Plan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#action-items" class="md-nav__link">
    <span class="md-ellipsis">
      Action Items
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mnist-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      MNIST dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modifications-to-the-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Modifications to the neural network
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-with-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      Learning with Gradient Descent
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Math for ML/DL
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Math for ML/DL
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math-for-ml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math-for-ml/gradient-descent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradient Descent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#making-perceptron-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Making Perceptron Learn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-activation" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Activation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#we-have-sigmoid-neurons" class="md-nav__link">
    <span class="md-ellipsis">
      We have Sigmoid Neurons
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#coding-feedforward-neural-networks-without-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Coding FeedForward Neural Networks (without learning)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lets-make-a-neural-network-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Let's make a Neural Network Learn.
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Let's make a Neural Network Learn.">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-beauty-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      The beauty of Neural Networks.
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-problem-and-the-dataset-setup" class="md-nav__link">
    <span class="md-ellipsis">
      The problem and the dataset setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The problem and the dataset setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-not-a-rule-based-approach" class="md-nav__link">
    <span class="md-ellipsis">
      Why not a rule-based approach?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-plan" class="md-nav__link">
    <span class="md-ellipsis">
      The Plan
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Plan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#action-items" class="md-nav__link">
    <span class="md-ellipsis">
      Action Items
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mnist-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      MNIST dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modifications-to-the-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Modifications to the neural network
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-with-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      Learning with Gradient Descent
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="learning-to-make-decisions">LEARNING to make decisions</h1>
<p>In the previous section, we looked at a basic perceptron model that takes in binary inputs <span class="arithmatex">\(x_i\)</span> and their corresponding weights <span class="arithmatex">\(w_i\)</span> and makes a binary decision between <code>Yes</code> or <code>No</code> (labelled <code>0</code> or <code>1</code>).  </p>
<p>However, we still cannot use the perceptron model because it is not <strong>trained</strong>. As the values for weights <span class="arithmatex">\(w_i\)</span> and bias <span class="arithmatex">\(b\)</span> are not optimal yet. <strong>This is exactly what we will discuss in this chapter. Making Neural Networks learn.</strong></p>
<h2 id="making-perceptron-learn">Making Perceptron Learn</h2>
<p>We have, with us a perceptron model, that makes binary decisions as follows:</p>
<p>Using <code>0</code> for YES and <code>1</code> for NO.</p>
<div class="arithmatex">\[
\text{output } = \left\{ \begin{matrix}
\text{0 if } \sum_j x_j w_j + b \geq 0\\ 
\text{1 if } \sum_j x_j w_j + b &lt; 0\\
\end{matrix}\right.
\]</div>
<p>The two parameters, above that control the output of the model are <code>weights</code> and <code>bias</code>. <strong>Changing values of weights and biases changes the output of the model (perceptron).</strong> If we would like to make an optimized models, we have to learn the optimal values of <code>weights</code> and <code>biases</code> for a given problem at hand for a given dataset.</p>
<p>In the above setting of perceptron we see that changing values of weights and bias can lead to any values on the real line output and with many features, slight changes in weights can lead to vast changes in the output, lets fix that using some function (called activation function) on top of the weighted output.</p>
<!-- We need an **activation function** that could help our Perceptron model to: -->
<div class="admonition info">
<p class="admonition-title">Why Activation Function?</p>
<ol>
<li>Accept any input on the real number line (instead of just binary inputs).</li>
<li>Make it possible that small changes to weights and bias would result in small changes to output so that we can come up with an algorithm to find the optimal values for <span class="arithmatex">\(w_i\)</span> and <span class="arithmatex">\(b\)</span>.</li>
<li>Scales the output of the perceptron between some values so that we can set an accept threshold along with the activation function.</li>
</ol>
</div>
<h2 id="sigmoid-activation">Sigmoid Activation</h2>
<p>Sigmoid (also called Logistic) function takes any input on the real line and returns value between 0 to 1. This works really well for our model as we can be sure that, no matter what the weights are, we know that the output of our model will be between 0 to 1. <strong>Importantly, this helps us to set a threshold of <code>0.5</code> to make decision.</strong> This is a very commonly accepted threshold in the field of Deep Learning.</p>
<div class="arithmatex">\[
\text{sigmoid(z)} = \sigma(z) = \frac{1}{1+e^{-z}}
\]</div>
<p>In our case, the perceptron output becomes</p>
<div class="arithmatex">\[
\text{output} = \text{sigmoid} ( \sum_j x_jw_j +b)
\]</div>
<p>Adding our threshold of <code>0.5</code> into the equation</p>
<div class="arithmatex">\[
\text{output } = \left\{ \begin{matrix}
\text{1 if } \sigma(\sum_j x_j w_j + b) \geq 0.5\\ 
\text{0 if } \sigma(\sum_j x_j w_j + b) &lt; 0.5\\
\end{matrix}\right.
\]</div>
<p>The sigmoid activation preserves our initial intuition that largely positive values lead to one decision and largely negative values lead to another decision. This still holds true after applying the sigmoid activation function as largely positive numbers shall be scaled closer to <code>1</code> and negative numbers are scaled towards <code>0</code>.</p>
<div class="admonition tip">
<p class="admonition-title">But does using sigmoid function change the way perceptron is modeled?</p>
<p>Let's take a look at the Sigmoid curve. To make sure that an inequality is maintained before and after a function is applied, there are some checks required to be passed.</p>
<ol>
<li>The function must be monotonically increasing or decreasing.</li>
<li>The function must be defined everywhere on the real number line.</li>
</ol>
<p><figure markdown="">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="../../assets/images/from-nns-to-llms/sigmoid.png"><img alt="" src="../../assets/images/from-nns-to-llms/sigmoid.png"/></a>
</figure></p>
<p>From the above figure we see that sigmoid function satisfies these conditions, which means adding sigmoid function does not effect the perceptron decision making inequality.</p>
<p>The crucial advantages of sigmoid activation:</p>
<ol>
<li>
<p>It gives a continuous, smooth function which leads to an important details that small changes in weights <span class="arithmatex">\(\Delta w_j\)</span> and bias <span class="arithmatex">\(\Delta b\)</span> will produce a small change in the output <span class="arithmatex">\(\Delta \text{output}\)</span>. This detail is crucial that helps the sigmoid neuron (perceptron) learn.</p>
</li>
<li>
<p>Sigmoid is differentiable throughout the number line. This is another crucial feature of sigmoid activation and shall be discussed in this chapter.</p>
</li>
</ol>
<div class="arithmatex">\[
\Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
\Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b,
\]</div>
<p>The above equation represents how the changes in output <span class="arithmatex">\(\Delta \text{output}\)</span> is a linear function of changes in weights <span class="arithmatex">\(\Delta w_j\)</span> and changes in bias <span class="arithmatex">\(\Delta b\)</span>.</p>
<p>This is derived from the equation:</p>
<div class="arithmatex">\[
\text{output} = \text{sigmoid} ( \sum_j x_jw_j +b)
\]</div>
<p>This linear dependence makes it easy for us to make small changes in weights and attain changes in output. <strong>This is what makes the learning possible.</strong> In other words, we are setting stage for our perceptron to learn.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Is Sigmoid the only activation function that makes learning possible?</p>
<p>Definitely not! Sigmoid activation function is one of the <strong>many Activation Functions</strong> present in the realm of Deep Learning. Even without the sigmoid activation, the perceptron can learn, however the learning would not be easier as changes in weights might drastically effect the output.</p>
<p>Other Activation Functions:</p>
<ol>
<li>Softmax Activation</li>
<li>ReLU Activation</li>
<li>Leaky ReLU Activation</li>
</ol>
<p>and many more exist, but for now lets focus on the sigmoid function and make our first learning neural network.</p>
</div>
<h2 id="we-have-sigmoid-neurons">We have Sigmoid Neurons</h2>
<ol>
<li>We have a sigmoid neuron unit (a variant of perceptron) that takes in any inputs on number line and weights to make a binary decision.</li>
<li>
<p class="annotate">Small changes to weights and bias makes small changes to output, this means we can come up with an algorithm to tune the values of <span class="arithmatex">\(w_i\)</span> and <span class="arithmatex">\(b\)</span> and find optimal values.(1)</p>
<ol>
<li>We still need a metric to denote what exactly optimal/good/bad means.</li>
</ol>
</li>
<li>
<p>Sigmoid activation also allows us to set a threshold of <code>0.5</code> to make decisions between two classes (<code>0</code> and <code>1</code>)</p>
</li>
</ol>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="http://neuralnetworksanddeeplearning.com/images/tikz8.png"><img alt="" src="http://neuralnetworksanddeeplearning.com/images/tikz8.png" width="500"/></a>
<figcaption>Why Sigmoid?
    <a href="http://neuralnetworksanddeeplearning.com/images/tikz8.png">Source</a>
</figcaption></p>
</figure>
<p>Sigmoid Neurons allows for the above architecture. We can stack up a bunch of sigmoid neurons as each of the neuron outputs a value between <code>0</code> and <code>1</code>. We can still use the threshold <code>0.5</code> for decision-making. This is wonderful for us because, <strong>all we need now is a learning algorithm to tweak the values of weights, and a metric to denote how good/bad output weights are for a given dataset.</strong></p>
<h2 id="neural-networks">Neural Networks</h2>
<p>Having understood the motivation and working of sigmoid neurons, we are now ready to understand a network of these artificial neurons as shown in the above figure, a Neural Network.</p>
<p>A Neural Network is a layered combination of artificial neurons (any activation function can be used to the output neurons to make a decision) as shown in the figure below. Each node is an artificial neuron and is connected to other neurons present at various LAYERS.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="http://neuralnetworksanddeeplearning.com/images/tikz10.png"><img alt="" src="http://neuralnetworksanddeeplearning.com/images/tikz10.png" width="500"/></a>
<figcaption>What is a Neural Network?
    <a href="http://neuralnetworksanddeeplearning.com/images/tikz10.png">Source</a>
</figcaption></p>
</figure>
<div class="admonition info">
<p class="admonition-title">Why the network architecture?</p>
<p>If you remember from the previous section, we modeled a perceptron based on the binary features we used to make a decision. In the initial case, these features are just simple Yes or No questions. However, not all features are simple and precise. There could be complex, abstract, interdependent features that lead to a decision. Hence we need network that could handle these cases.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Terminology</p>
<ol>
<li>The first layer of a neural network like the above one is known as the <strong>input layer</strong>, as it takes inputs to the network (like the Dendrites in a biological neuron).</li>
<li>The final layer that provides the output of a neural network is known as the <strong>output layer</strong>. This output layer could be connected to other networks. The output layer might contains one or more neurons (more on this later). For simplicity consider <strong>one output neuron that makes a binary decision.</strong> </li>
<li>The layers that come after the input layer and before the final output layer are known as the <strong>hidden layers.</strong></li>
</ol>
<p><figure markdown="">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="http://neuralnetworksanddeeplearning.com/images/tikz11.png"><img alt="" src="http://neuralnetworksanddeeplearning.com/images/tikz11.png" width="500"/></a>
<figcaption>Anatomy of a neural network
    <a href="http://neuralnetworksanddeeplearning.com/images/tikz11.png">Source</a>
</figcaption>
</figure></p>
<p><strong>The above neural network is sometimes also known as a Multi-Layer Perceptron (MLP) or Feedforward Neural Networks as the information flow is in the left-to-right (forward) direction.</strong></p>
</div>
<h2 id="coding-feedforward-neural-networks-without-learning">Coding FeedForward Neural Networks (without learning)</h2>
<p><a href="https://colab.research.google.com/drive/1DL4GgeAwFupdV8sgI4h0BPP9febwl-FK?usp=sharing"><img alt="" src="https://colab.research.google.com/assets/colab-badge.svg"/></a> (Use <span class="keys"><kbd class="key-control">Ctrl</kbd></span> + click to open in new tab)</p>
<!-- <a href="https://colab.research.google.com/drive/1DL4GgeAwFupdV8sgI4h0BPP9febwl-FK?usp=sharing" target="_blank">
    <a class="glightbox" href="https://colab.research.google.com/assets/colab-badge.svg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
</a>(Opens in a new tab) -->
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">class</span> <span class="nc">Perceptron</span><span class="p">:</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 1 (To test the architecture)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="k">def</span> <span class="nf">activate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="c1"># Using the sigmoid activation function on every neuron</span>
<a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">))</span> <span class="c1"># value (To test code correctness)</span>
<a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a href="#__codelineno-0-11" id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="k">class</span> <span class="nc">Layer</span><span class="p">:</span>
<a href="#__codelineno-0-12" id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_neurons</span><span class="p">):</span>
<a href="#__codelineno-0-13" id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span> <span class="o">=</span> <span class="p">[</span><span class="n">Perceptron</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_neurons</span><span class="p">)]</span>
<a href="#__codelineno-0-14" id="__codelineno-0-14" name="__codelineno-0-14"></a>
<a href="#__codelineno-0-15" id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<a href="#__codelineno-0-16" id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">neuron_values</span> <span class="o">=</span> <span class="p">[]</span>
<a href="#__codelineno-0-17" id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="k">for</span> <span class="n">neuron</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="p">:</span>
<a href="#__codelineno-0-18" id="__codelineno-0-18" name="__codelineno-0-18"></a>          <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span>
<a href="#__codelineno-0-19" id="__codelineno-0-19" name="__codelineno-0-19"></a>          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
<a href="#__codelineno-0-20" id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="n">value</span><span class="o">+=</span> <span class="n">i</span><span class="o">*</span><span class="n">neuron</span><span class="o">.</span><span class="n">weight</span>
<a href="#__codelineno-0-21" id="__codelineno-0-21" name="__codelineno-0-21"></a>          <span class="n">neuron_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neuron</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
<a href="#__codelineno-0-22" id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="k">return</span> <span class="n">neuron_values</span>            
<a href="#__codelineno-0-23" id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a href="#__codelineno-0-24" id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a href="#__codelineno-0-25" id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">:</span>
<a href="#__codelineno-0-26" id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
<a href="#__codelineno-0-27" id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
<a href="#__codelineno-0-28" id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a href="#__codelineno-0-29" id="__codelineno-0-29" name="__codelineno-0-29"></a>        <span class="c1"># Input layer</span>
<a href="#__codelineno-0-30" id="__codelineno-0-30" name="__codelineno-0-30"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Layer</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">))</span>
<a href="#__codelineno-0-31" id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a href="#__codelineno-0-32" id="__codelineno-0-32" name="__codelineno-0-32"></a>        <span class="c1"># Hidden layers</span>
<a href="#__codelineno-0-33" id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">hidden_layers</span><span class="p">:</span>
<a href="#__codelineno-0-34" id="__codelineno-0-34" name="__codelineno-0-34"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Layer</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<a href="#__codelineno-0-35" id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a href="#__codelineno-0-36" id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="c1"># Output layer</span>
<a href="#__codelineno-0-37" id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Layer</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">))</span>
<a href="#__codelineno-0-38" id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a href="#__codelineno-0-39" id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<a href="#__codelineno-0-40" id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span> <span class="c1"># we dont want to compute values again for inputs as we already have them.</span>
<a href="#__codelineno-0-41" id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<a href="#__codelineno-0-42" id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="k">return</span> <span class="n">inputs</span>
<a href="#__codelineno-0-43" id="__codelineno-0-43" name="__codelineno-0-43"></a>
<a href="#__codelineno-0-44" id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="c1"># Define the network</span>
<a href="#__codelineno-0-45" id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="n">num_inputs</span> <span class="o">=</span> <span class="mi">4</span>
<a href="#__codelineno-0-46" id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<a href="#__codelineno-0-47" id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="n">num_outputs</span> <span class="o">=</span> <span class="mi">1</span>
<a href="#__codelineno-0-48" id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a href="#__codelineno-0-49" id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="n">network</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<a href="#__codelineno-0-50" id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a href="#__codelineno-0-51" id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="c1"># Input values</span>
<a href="#__codelineno-0-52" id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<a href="#__codelineno-0-53" id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a href="#__codelineno-0-54" id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="c1"># Get the output</span>
<a href="#__codelineno-0-55" id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="n">output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a href="#__codelineno-0-56" id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<a href="#__codelineno-0-57" id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="nb">print</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">output</span><span class="o">&gt;=</span><span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<strong>But where did the bias go?</strong>
Every perceptron node comes with a corresponding bias as discussed before. However, most literature ignores bias (or incorporates this variable within the weight) as with an without bias the output of neuron after activation (sigmoid for example) falls within a range.</p>
<p>Hence to remove extra learnable paramters, bias is incorporated into the weight itself and the challenge boils down to finding the optimal weights of each neuron.</p>
<p>If you still want to explicitly maintain a bias term, the perceptron class and Layer class can be changed to</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">class</span> <span class="nc">Perceptron</span><span class="p">:</span>
<a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Initialize bias</span>
<a href="#__codelineno-1-5" id="__codelineno-1-5" name="__codelineno-1-5"></a>
<a href="#__codelineno-1-6" id="__codelineno-1-6" name="__codelineno-1-6"></a>    <span class="k">def</span> <span class="nf">activate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<a href="#__codelineno-1-7" id="__codelineno-1-7" name="__codelineno-1-7"></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">))</span>  <span class="c1"># Sigmoid activation</span>
<a href="#__codelineno-1-8" id="__codelineno-1-8" name="__codelineno-1-8"></a>
<a href="#__codelineno-1-9" id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="c1"># Layer class</span>
<a href="#__codelineno-1-10" id="__codelineno-1-10" name="__codelineno-1-10"></a><span class="n">value</span><span class="o">+=</span> <span class="n">i</span><span class="o">*</span><span class="n">neuron</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="n">neuron</span><span class="o">.</span><span class="n">bias</span>
</code></pre></div>
<p>The above code implements a basic feedforward neural network without any learning component. This is a great place to start. All we want now is an <strong>algorithm</strong> to find the optimal values for weights to make decisions on <strong>unseen data points</strong>.</p>
<h2 id="lets-make-a-neural-network-learn">Let's make a Neural Network Learn.</h2>
<ol>
<li>We have a neural network that accepts inputs.</li>
<li>Hidden layers calculate weighted sum to transmit information.</li>
<li>We have an activation function for each neuron.</li>
<li>Each neuron has a weight and the optimal values of these weights have to be learnt.</li>
</ol>
<div class="arithmatex">\[
\text{output } (y_i) = \text{sigmoid}(\sum_j x_jw_j+b)
\]</div>
<div class="admonition quote">
<p class="admonition-title">ANNs</p>
<p>Artificial Neural Networks and Deep Learning models learn from a bunch of examples.</p>
</div>
<h3 id="the-beauty-of-neural-networks">The beauty of Neural Networks.</h3>
<p>If you didn't realize, the neural networks are built in this way to facilitate learning from examples.</p>
<ol>
<li>First we define a task at hand (such as image recognition).</li>
<li>We collect data for the task that has a bunch of data points and their corresponding ground truth output. Think in terms of math that we will have <span class="arithmatex">\(x_i\)</span> and <span class="arithmatex">\(\text{output}\)</span> for each data point.</li>
<li>We randomly initialize weights of each neuron in the network and make predictions (random predictions which are intially very wrong).</li>
<li>We define a metric that helps us understand the correctness of neural network predictions.</li>
<li>We use an <strong>algorithm</strong> that tunes the values of weights of neurons in neural network such that the correctness in prediction of our network is maximized. This algorithm is the learning process of the network (also known as training).</li>
<li>Upon training, we will have the optimal values for all the weights <span class="arithmatex">\(w_i\)</span>. </li>
<li>These weights are then used to predict values for unseen inputs using our trained model.</li>
</ol>
<h3 id="the-problem-and-the-dataset-setup">The problem and the dataset setup</h3>
<p>To train our first Neural Network we are going to use the classic MNIST dataset for digit recognition. Below is a snapshot of some images in the dataset.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="http://neuralnetworksanddeeplearning.com/images/digits_separate.png"><img alt="" src="http://neuralnetworksanddeeplearning.com/images/digits_separate.png" width="500"/></a>
<figcaption>MNIST dataset example images.
    <a href="http://neuralnetworksanddeeplearning.com/images/digits_separate.png">Source</a>
</figcaption></p>
</figure>
<p>The plan is to send a bunch of example data points (image information) and labels to the neural network and train the neural network to recognize and distinguish between numbers between 0 to 9.</p>
<h4 id="why-not-a-rule-based-approach">Why not a rule-based approach?</h4>
<p>Think about the brute-force way one would solve digit recognition. In our minds we have specific representation of digits and with immense ease we can distinguish between digits very easily. However, that ease is deceptive. Image if we wanted to come up with specific rules to distinguish digits. </p>
<p>The number of rules required to make such an algorithm would blow up very quickly as there could be numerous ways in which each digit can be written. Take a look at the below image for example.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="https://miro.medium.com/v2/resize:fit:1200/1*w7pBsjI3t3ZP-4Gdog-JdQ.png"><img alt="" src="https://miro.medium.com/v2/resize:fit:1200/1*w7pBsjI3t3ZP-4Gdog-JdQ.png" width="500"/></a>
<figcaption>Rule based approach does not work as there could be numerous ways to represent every digit differently.
    <a href="https://miro.medium.com/v2/resize:fit:1200/1*w7pBsjI3t3ZP-4Gdog-JdQ.png">Source</a>
</figcaption></p>
</figure>
<p>Hence, we <strong>need</strong> a learning algorithm that could figure out the underlying patterns within all these digits and distinguish between various digits automatically after training. This will be our first <strong>Learning Algorithm</strong> that we will implement from scratch.</p>
<h3 id="the-plan">The Plan</h3>
<pre class="mermaid"><code>graph LR
  A("Gather Data
   (Digit Images)") --&gt; B[Pre-Process Data to feed
   into Neural Network] --&gt; C[Devise a 
   Learning Algorithm]
   --&gt; D[Initialize the 
   Neural Network] --&gt; E[Train using the 
   pre-processed dataset] --&gt; F(Predict on new data points 
   not present in training dataset);</code></pre>
<h4 id="action-items">Action Items</h4>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Gather data containing digit images and labels (MNIST).</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Pre-Process the dataset so that Neural Network (NN) can accept the data.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Split the data into train and test. We want to save some data to test the model's performance.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Build a learning algorithm that can be used by <strong>any</strong> NN to train on input data.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Train on the pre-processed train dataset.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Evaluate on the test dataset.</li>
</ul>
<h3 id="mnist-dataset">MNIST dataset</h3>
<p>There are numerous ways to get the MNIST dataset as its quite a famous dataset. The original dataset was release by Dr. Yann Lecun et. al., and can be downloaded <a href="http://yann.lecun.com/exdb/mnist/index.html">here</a>. (The link does not open on chromium based browsers, try safari or firefox browsers, but <code>wget</code> still works).</p>
<p>MNIST dataset is a collection of 60,000 images of hand-written digits. Each image has a dimension of <span class="arithmatex">\(28 \times 28\)</span>. <strong>How do we process this dataset?</strong> Every value in the image represents a pixel intensity. The way we modeled input layer of the neural network, it should be able accept any input on the number line.</p>
<p>However, how to we process 2-dimensional data? One neat trick is to flatten the <span class="arithmatex">\(28 \times 28\)</span> into a 1-D vector of size <span class="arithmatex">\(728\)</span>. Then we can feed these <span class="arithmatex">\(728\)</span> values into the input layer of the neural network. That's exactly what we are going to do.</p>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="kn">from</span> <span class="nn">urllib</span> <span class="kn">import</span> <span class="n">request</span>
<a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="kn">import</span> <span class="nn">gzip</span>
<a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="kn">import</span> <span class="nn">pickle</span>
<a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a>
<a href="#__codelineno-2-6" id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="n">filename</span> <span class="o">=</span> <span class="p">[</span>
<a href="#__codelineno-2-7" id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="p">[</span><span class="s2">"training_images"</span><span class="p">,</span><span class="s2">"train-images-idx3-ubyte.gz"</span><span class="p">],</span>
<a href="#__codelineno-2-8" id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="p">[</span><span class="s2">"test_images"</span><span class="p">,</span><span class="s2">"t10k-images-idx3-ubyte.gz"</span><span class="p">],</span>
<a href="#__codelineno-2-9" id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="p">[</span><span class="s2">"training_labels"</span><span class="p">,</span><span class="s2">"train-labels-idx1-ubyte.gz"</span><span class="p">],</span>
<a href="#__codelineno-2-10" id="__codelineno-2-10" name="__codelineno-2-10"></a><span class="p">[</span><span class="s2">"test_labels"</span><span class="p">,</span><span class="s2">"t10k-labels-idx1-ubyte.gz"</span><span class="p">]</span>
<a href="#__codelineno-2-11" id="__codelineno-2-11" name="__codelineno-2-11"></a><span class="p">]</span>
<a href="#__codelineno-2-12" id="__codelineno-2-12" name="__codelineno-2-12"></a>
<a href="#__codelineno-2-13" id="__codelineno-2-13" name="__codelineno-2-13"></a><span class="k">def</span> <span class="nf">download_mnist</span><span class="p">():</span>
<a href="#__codelineno-2-14" id="__codelineno-2-14" name="__codelineno-2-14"></a>    <span class="n">base_url</span> <span class="o">=</span> <span class="s2">"http://yann.lecun.com/exdb/mnist/"</span>
<a href="#__codelineno-2-15" id="__codelineno-2-15" name="__codelineno-2-15"></a>    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">filename</span><span class="p">:</span>
<a href="#__codelineno-2-16" id="__codelineno-2-16" name="__codelineno-2-16"></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">"Downloading "</span><span class="o">+</span><span class="n">name</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="s2">"..."</span><span class="p">)</span>
<a href="#__codelineno-2-17" id="__codelineno-2-17" name="__codelineno-2-17"></a>        <span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">base_url</span><span class="o">+</span><span class="n">name</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a href="#__codelineno-2-18" id="__codelineno-2-18" name="__codelineno-2-18"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Download complete."</span><span class="p">)</span>
<a href="#__codelineno-2-19" id="__codelineno-2-19" name="__codelineno-2-19"></a>
<a href="#__codelineno-2-20" id="__codelineno-2-20" name="__codelineno-2-20"></a><span class="k">def</span> <span class="nf">save_mnist</span><span class="p">():</span>
<a href="#__codelineno-2-21" id="__codelineno-2-21" name="__codelineno-2-21"></a>    <span class="n">mnist</span> <span class="o">=</span> <span class="p">{}</span>
<a href="#__codelineno-2-22" id="__codelineno-2-22" name="__codelineno-2-22"></a>    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">filename</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
<a href="#__codelineno-2-23" id="__codelineno-2-23" name="__codelineno-2-23"></a>        <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">name</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a href="#__codelineno-2-24" id="__codelineno-2-24" name="__codelineno-2-24"></a>            <span class="n">mnist</span><span class="p">[</span><span class="n">name</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<a href="#__codelineno-2-25" id="__codelineno-2-25" name="__codelineno-2-25"></a>    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">filename</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]:</span>
<a href="#__codelineno-2-26" id="__codelineno-2-26" name="__codelineno-2-26"></a>        <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">name</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a href="#__codelineno-2-27" id="__codelineno-2-27" name="__codelineno-2-27"></a>            <span class="n">mnist</span><span class="p">[</span><span class="n">name</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<a href="#__codelineno-2-28" id="__codelineno-2-28" name="__codelineno-2-28"></a>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"mnist.pkl"</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a href="#__codelineno-2-29" id="__codelineno-2-29" name="__codelineno-2-29"></a>        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
<a href="#__codelineno-2-30" id="__codelineno-2-30" name="__codelineno-2-30"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Save complete."</span><span class="p">)</span>
<a href="#__codelineno-2-31" id="__codelineno-2-31" name="__codelineno-2-31"></a>
<a href="#__codelineno-2-32" id="__codelineno-2-32" name="__codelineno-2-32"></a><span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
<a href="#__codelineno-2-33" id="__codelineno-2-33" name="__codelineno-2-33"></a>    <span class="n">download_mnist</span><span class="p">()</span>
<a href="#__codelineno-2-34" id="__codelineno-2-34" name="__codelineno-2-34"></a>    <span class="n">save_mnist</span><span class="p">()</span>
<a href="#__codelineno-2-35" id="__codelineno-2-35" name="__codelineno-2-35"></a>
<a href="#__codelineno-2-36" id="__codelineno-2-36" name="__codelineno-2-36"></a><span class="k">def</span> <span class="nf">load</span><span class="p">():</span>
<a href="#__codelineno-2-37" id="__codelineno-2-37" name="__codelineno-2-37"></a>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"mnist.pkl"</span><span class="p">,</span><span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a href="#__codelineno-2-38" id="__codelineno-2-38" name="__codelineno-2-38"></a>        <span class="n">mnist</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<a href="#__codelineno-2-39" id="__codelineno-2-39" name="__codelineno-2-39"></a>    <span class="k">return</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">"training_images"</span><span class="p">],</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">"training_labels"</span><span class="p">],</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">"test_images"</span><span class="p">],</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">"test_labels"</span><span class="p">]</span>
<a href="#__codelineno-2-40" id="__codelineno-2-40" name="__codelineno-2-40"></a>
<a href="#__codelineno-2-41" id="__codelineno-2-41" name="__codelineno-2-41"></a><span class="n">init</span><span class="p">()</span>
<a href="#__codelineno-2-42" id="__codelineno-2-42" name="__codelineno-2-42"></a><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load</span><span class="p">()</span>
</code></pre></div>
We have loaded the data in the form of numpy arrays into <code>x_train</code>, <code>y_train</code>, <code>x_test</code>, <code>y_test</code>. All of the train arrays are numpy arrays containing the pixel value of each image as vectors of size <span class="arithmatex">\(728\)</span>.</p>
<p>If we plot the first image of the dataset, we see the following image</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a>
<a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="n">img</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span> <span class="c1"># First image in the training set.</span>
<a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># Show the image</span>
</code></pre></div>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRZAU8v7SOUEd4xGvJxutSB6NcVHCgqdhyH-4v3n3BHsF_D_YvoE_wP9PTs_aE7sbQCKEU&amp;usqp=CAU"><img alt="" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRZAU8v7SOUEd4xGvJxutSB6NcVHCgqdhyH-4v3n3BHsF_D_YvoE_wP9PTs_aE7sbQCKEU&amp;usqp=CAU"/></a></p>
<h3 id="modifications-to-the-neural-network">Modifications to the neural network</h3>
<p>Until now, we had a neural network that makes a binary decision. How do we modify the network to make a multi-class classification.</p>
<p>One way is to add as many number of neurons in the output layers as the number of classes present in the datset. This means the final layer for the MNIST digit classification network contains <code>10</code> output neurons as there are <code>10</code> classes <code>0, 1, 2, 3, 4, 5, 6, 7, 8, 9</code>. The number of hidden layers and nodes in each layers is upto us. The input and output layers are the ones that are required to be modified.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="http://neuralnetworksanddeeplearning.com/images/tikz12.png"><img alt="" src="http://neuralnetworksanddeeplearning.com/images/tikz12.png" width="500"/></a>
<figcaption>A possible neural network to classify MNIST digits.
    <a href="http://neuralnetworksanddeeplearning.com/images/tikz12.png">Source</a>
</figcaption></p>
</figure>
<p>In the above network, <strong>we use one neuron per class</strong>. This means based on the neuron that is activated for a given image, we classify the input image. Of course, testing unseen images happens after the training is complete. During training we tune the weights of neurons in a way that representations, patterns and intricacies between images and labels are learnt by the network.</p>
<p><strong>What if more than one neuron in the output layer is activated for an image?</strong></p>
<p>In the above network setting, there is a possibility that for a given image, exmaple an image of 5, both 4th and 5th neurons in the output layers, which label do you assign. Softmax is yet another activation function that can be used in this case.</p>
<p><strong>Softmax Activation</strong> (for the final layer).</p>
<p>Softmax function takes in an array of inputs and gives a probability measure for each input value. Using softmax activation we can take <code>argmax</code> of output values and the label with maximum probability is returned. (As I said before, there could many activation functions). (Sigmoid and Softmax are two of the many).</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input checked="" disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Gather data containing digit images and labels (MNIST).</li>
<li class="task-list-item"><label class="task-list-control"><input checked="" disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Pre-Process the dataset so that Neural Network (NN) can accept the data.</li>
<li class="task-list-item"><label class="task-list-control"><input checked="" disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Split the data into train and test. We want to save some data to test the model's performance.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Build a learning algorithm that can be used by <strong>any</strong> NN to train on input data.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Train on the pre-processed train dataset.</li>
<li class="task-list-item"><label class="task-list-control"><input disabled="" type="checkbox"/><span class="task-list-indicator"></span></label> Evaluate on the test dataset.</li>
</ul>
<h2 id="learning-with-gradient-descent">Learning with Gradient Descent</h2>
<p>Now as we have the dataset and the Neural Network ready, the next step for us to think of a way to make the model learn.</p>
<p>We will use the notation <span class="arithmatex">\(X\)</span> to denote the training input. Each training input <span class="arithmatex">\(X_i\)</span> is a <span class="arithmatex">\(28 \times 28 = 728\)</span> dimensional vector.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../decision-making-and-nns/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Decision Making and Neurons">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Decision Making and Neurons
              </div>
            </div>
          </a>
        
        
          
          <a href="../../math-for-ml/" class="md-footer__link md-footer__link--next" aria-label="Next: Introduction">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Introduction
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.path", "navigation.prune", "navigation.top", "search.highlight", "search.suggest", "content.tabs.link", "content.code.copy", "navigation.footer"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.caa56a14.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>